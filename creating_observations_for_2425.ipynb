{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "center-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from models.panel import PanelData\n",
    "from models.episode import EpisodeModel\n",
    "from feature_extraction.methods import episode_dynamics_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "serial-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_2425 = pd.read_csv('_data/mimic_2425.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "still-texas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Unnamed: 0    RR   SPO2   MAP   SBP   DBP     HR    PP       CO\n",
      "0  2020-10-18 15:24:25  35.0   99.9   0.0   0.0   0.0  106.9   0.0     0.00\n",
      "1  2020-10-18 15:25:25  36.4  100.0  87.0  98.9  63.1  107.3  35.8  3841.34\n",
      "2  2020-10-18 15:26:25  35.2  100.0  75.2  97.9  63.0  107.5  34.9  3751.75\n"
     ]
    }
   ],
   "source": [
    "print(mimic_2425.head(3))\n",
    "# raw time series with minute by minute entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mounted-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12877, 8)\n"
     ]
    }
   ],
   "source": [
    "mimic_2425 = mimic_2425.drop('Unnamed: 0', axis=1)\n",
    "print(mimic_2425.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "apparent-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_model = PanelData(prototype=mimic_2425,\n",
    "                       periods=(60, 60, 30))\n",
    "# class I created to handle data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "civilian-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['MAP', 'DBP', 'SBP', 'HR']:\n",
    "    mimic_2425[col] = mimic_2425[col].where(mimic_2425[col].between(10, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "technical-christmas",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_specs = \\\n",
    "    dict(\n",
    "        hypotension=dict(above_threshold=False,\n",
    "                         value_threshold=60,\n",
    "                         ratio_threshold=0.9,\n",
    "                         target_variable='MAP'),\n",
    "        tachycardia=dict(above_threshold=True,\n",
    "                         value_threshold=100,\n",
    "                         ratio_threshold=0.9,\n",
    "                         target_variable='HR'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mediterranean-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the observations\n",
    "X, y = [], []\n",
    "for i in np.arange(data_model.episode_len, mimic_2425.shape[0] + 1):\n",
    "    # a for loop that goes from the episode duration (60min+60min+30min = 150 time series points) \n",
    "    # to the length of the episode\n",
    "    \n",
    "    indices = np.arange(i - data_model.episode_len, i)\n",
    "\n",
    "    # an episode is a 150 window with the obser. period + warning period + target period\n",
    "    episode = mimic_2425.iloc[indices, :]\n",
    "    \n",
    "    # getting features from the episode\n",
    "    # the method .data_points_predictors automatically retrieves the observation period only\n",
    "    X_i, episode_is_valid = data_model.data_points_predictors(episode, predictors_fun=episode_dynamics_dummy)\n",
    "\n",
    "    \n",
    "    if not episode_is_valid:\n",
    "        X.append(X_i)\n",
    "        y.append(np.nan)\n",
    "    else:\n",
    "        y_i_spot = data_model.spot_threshold_target(episode, **target_specs['hypotension'])\n",
    "        X.append(X_i)\n",
    "        y.append(y_i_spot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "perfect-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat(X, axis=1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "published-charlotte",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     RR_mean  SPO2_mean   MAP_mean   SBP_mean   DBP_mean     HR_mean  \\\n",
      "0  14.345000  98.133333  67.820339  88.091071  56.767857  103.928333   \n",
      "1  13.761667  98.118333  67.825000  87.971930  56.840351  103.826667   \n",
      "2  13.155000  98.098333  67.506667  87.666667  56.791228  103.726667   \n",
      "3  12.631667  98.075000  67.348333  87.401754  56.668421  103.615000   \n",
      "4  12.065000  98.056667  67.183333  87.135088  56.542105  103.505000   \n",
      "\n",
      "     PP_mean      CO_mean  RR_SPO2_ccf  RR_MAP_ccf  ...  SBP_DBP_ccf  \\\n",
      "0  29.235000  3042.300667      3465.00     2338.00  ...     5179.755   \n",
      "1  29.575000  3076.572667      3603.60     2478.84  ...     6023.010   \n",
      "2  29.331667  3048.343000      3477.76     2390.08  ...     5903.370   \n",
      "3  29.196667  3030.837833      3352.40     2233.80  ...     5443.200   \n",
      "4  29.063333  3013.634167      3451.61     2265.01  ...     5308.800   \n",
      "\n",
      "    SBP_HR_ccf  SBP_PP_ccf     SBP_CO_ccf   DBP_HR_ccf  DBP_PP_ccf  \\\n",
      "0  8923.625536  1911.57625  193642.674125  5750.583929   1231.8625   \n",
      "1  9969.120000  2017.56000  203370.048000  6360.480000   1287.2400   \n",
      "2  9917.270000  2075.48000  210246.124000  6381.900000   1335.6000   \n",
      "3  9797.760000  2604.96000  262579.968000  6300.000000   1675.0000   \n",
      "4  9638.400000  2563.20000  257345.280000  6224.800000   1655.4000   \n",
      "\n",
      "     DBP_CO_ccf  HR_PP_ccf   HR_CO_ccf  PP_CO_ccf  \n",
      "0  124787.67125    2319.73  234988.649      0.000  \n",
      "1  129753.79200    2188.92  220643.136  73616.256  \n",
      "2  135296.28000    2279.00  230862.700  74949.844  \n",
      "3  168840.00000    2867.60  289054.080  93739.968  \n",
      "4  166202.16000    2856.90  286832.760  91143.120  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "(12728, 36)\n"
     ]
    }
   ],
   "source": [
    "#dummy predictors, the real ones are more extensive\n",
    "print(X.head())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wanted-spelling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12728\n",
      "0.0    12580\n",
      "1.0       19\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(y))\n",
    "print(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sporting-avenue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    0.988372\n",
      "1.0    0.001493\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(y).value_counts() / len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deluxe-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['target'] = y\n",
    "# so, we got the RAW observations without any restriction\n",
    "# we will do it now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pointed-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_model = EpisodeModel(target_variable='target',\n",
    "                        min_ep_duration=150,\n",
    "                        max_event_duration=60, \n",
    "                        positive_entities_only = True)\n",
    "# the minimum duration of an episode is 150 data points, which is fine in this case\n",
    "# if an AHE event takes longer than 60 min, we truncate the rest of the observations because then predicting anything\n",
    "# is useless in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "copyrighted-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we split the entity by activity. e.g. if an entity contains two different event, these will be two separate episodes\n",
    "# besides, we truncate the event duration to 60min (max_event_duration)\n",
    "X_split = ep_model.episode_split(X, \n",
    "                                 target_variable=ep_model.target_variable, \n",
    "                                 min_ep_duration=ep_model.min_ep_duration,\n",
    "                                 max_event_duration=ep_model.max_event_duration)\n",
    "\n",
    "X_split_df0 = pd.concat(X_split)\n",
    "\n",
    "# then, for each sub episode, we sample the data every 30 min (sample_interval_size)\n",
    "# this will basically reduce the dataset, as the distribution of the class should remain the same\n",
    "for k in X_split:\n",
    "    X_split[k] = \\\n",
    "        ep_model.non_overlapping_resample(episode=X_split[k],\n",
    "                                      target_variable=ep_model.target_variable,\n",
    "                                      sample_interval_size=30,\n",
    "                                      include_class_condition=True)\n",
    "    \n",
    "X_split_df = pd.concat(X_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "whole-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11073, 37)\n",
      "0.0    0.998555\n",
      "1.0    0.001355\n",
      "Name: target, dtype: float64\n",
      "(385, 37)\n",
      "0.0    0.961039\n",
      "1.0    0.038961\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(X_split_df0.shape)\n",
    "print(X_split_df0['target'].value_counts() / X_split_df0.shape[0])\n",
    "\n",
    "print(X_split_df.shape)\n",
    "print(X_split_df['target'].value_counts() / X_split_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intended-familiar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print((X_split_df['target'] > 0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "herbal-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print((X_split_df['target'].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-permission",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paneldata",
   "language": "python",
   "name": "paneldata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
